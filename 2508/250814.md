시각화 오토인코더 리뷰
잠재공간을 조작하기 위해 필요한 수학적 성질 2가지
	1. 일대일 대응, 2. 지역적 평활성
![vae 아키텍처](<../Assets/VAE 아키텍처.png>)![vae 정정부분](<../Assets/VAE 정정부분.png>)
여기서 $P^{n_v}$을 $v_d$을 통해 $n_l$차원의 $P_0^{n_l}$로 매핑하고, 다시 $f_d$을 통해 $n_0$차원의 $P_v^{n_0}$로 매핑한 것을 표현하면 figure4와 같다.
여기서 $P_0^{n_l} \rightarrow P_v^{n_l}$ 로 정정해아 할듯.

abTanh함수: a\*Tanh(b\*x) 가 맞는지 확인
이때 a는 출력값(뉴런이 내보내는 신호의 세기) 치역을 조절
b는 함수의 기울기(뉴런이 얼마나 민감하게 반응할지)를 조절(b가 커질수록 계단함수 꼴)

생성 오토인코더 GAE
논문에서 제시한 K-Lipschitz 연속 함수 가정은 시각화 AE에서 가정한 지역적 평활성과 같은 말 아닌가?

다양체 가설: 고차원 공간 위 고차원 데이터들은 해당 고차원에 속하지만 부분공간은 아닌 어떤 휘어진 형태의 공간 위에 매핑될 수 있다. 이때 이 형태를 manifold라고 명명한다.
이 manifold는 연속성을 가지는가?
어떤 함수로 정의할 수 있는가?
AE의 잠재공간은 이 manifold를 학습한 저차원 공간인가?

VAE는 재구성 오차와 통계적 분포 추정 두가지를 잘해야하는데 VAE의 성능 저하문제가 한번에 두가지를 잡으려고 하니까...
그럼 재구성 오차먼저 줄인 후에 분포를 추정하고 샘플링
생성 모델의 성능은 재구성 오차가 충분히 작을때만 의미가 있음.

신경망에 가중치들을 최적화하는데 왜 활성화함수는 파라메틱하게 바꿀 생각을 못했을까
그러면 좀 더 신경망에 비선형성을 추가할 수 있지 않을까?